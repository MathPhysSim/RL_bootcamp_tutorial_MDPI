@Article{Scheinker2020,
  author  = {Scheinker, Alexander and Hirlaender, Simon and Velotti, Francesco Maria and Gessner, Spencer and Della Porta, Giovanni Zevi and Kain, Verena and Goddard, Brennan and Ramjiawan, Rebecca},
  journal = {AIP Advances},
  title   = {Online multi-objective particle accelerator optimization of the AWAKE electron beam line for simultaneous emittance and orbit control},
  year    = {2020},
  issn    = {2158-3226},
  month   = {05},
  number  = {5},
  pages   = {055320},
  volume  = {10},
  doi     = {10.1063/5.0003423},
  eprint  = {https://pubs.aip.org/aip/adv/article-pdf/doi/10.1063/5.0003423/12846285/055320\_1\_online.pdf},
  url     = {https://doi.org/10.1063/5.0003423},
}

@Article{Kain2020,
  author    = {Kain, Verena and Hirlander, Simon and Goddard, Brennan and Velotti, Francesco Maria and Della Porta, Giovanni Zevi and Bruchon, Niky and Valentino, Gianluca},
  journal   = {Phys. Rev. Accel. Beams},
  title     = {Sample-efficient reinforcement learning for CERN accelerator control},
  year      = {2020},
  month     = {Dec},
  pages     = {124801},
  volume    = {23},
  doi       = {10.1103/PhysRevAccelBeams.23.124801},
  issue     = {12},
  numpages  = {12},
  publisher = {American Physical Society},
  url       = {https://link.aps.org/doi/10.1103/PhysRevAccelBeams.23.124801},
}

@InProceedings{Kain2022,
  author = {Verena Kain and Niky Bruchon and Simon Hirlaender and Nico Madysa and I. Vojskovic and Piotr Krzysztof Skowronski and Gianluca Valentino},
  title  = {TEST OF MACHINE LEARNING AT THE CERN LINAC4},
  year   = {2022},
  url    = {https://api.semanticscholar.org/CorpusID:252460155},
}

@InProceedings{Kamthe2018,
  author    = {Kamthe, Sanket and Deisenroth, Marc},
  booktitle = {Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics},
  title     = {Data-Efficient Reinforcement Learning with Probabilistic Model Predictive Control},
  year      = {2018},
  editor    = {Storkey, Amos and Perez-Cruz, Fernando},
  month     = {09--11 Apr},
  pages     = {1701--1710},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {84},
  abstract  = {Trial-and-error based reinforcement learning (RL) has seen rapid advancements in recent times, especially with the advent of deep neural networks. However, the majority of autonomous RL algorithms require a large number of interactions with the environment. A large number of interactions may be impractical in many real-world applications, such as robotics, and many practical systems have to obey limitations in the form of state space or control constraints. To reduce the number of system interactions while simultaneously handling constraints, we propose a model-based RL framework based on probabilistic Model Predictive Control (MPC). In particular, we propose to learn a probabilistic transition model using Gaussian Processes (GPs) to incorporate model uncertainty into long-term predictions, thereby, reducing the impact of model errors. We then use MPC to find a control sequence that minimises the expected long-term cost. We provide theoretical guarantees for first-order optimality in the GP-based transition models with deterministic approximate inference for long-term planning. We demonstrate that our approach does not only achieve state-of-the-art data efficiency, but also is a principled way for RL in constrained environments.},
  pdf       = {http://proceedings.mlr.press/v84/kamthe18a/kamthe18a.pdf},
  url       = {https://proceedings.mlr.press/v84/kamthe18a.html},
}

@Article{Hirlaender2023,
  author  = {Hirlaender, Simon and Lamminger, Lukas and Zevi Della Porta, Giovanni and Kain, Verena},
  journal = {JACoW IPAC},
  title   = {{Ultra fast reinforcement learning demonstrated at CERN AWAKE}},
  year    = {2023},
  pages   = {THPL038},
  volume  = {2023},
  doi     = {10.18429/JACoW-IPAC2023-THPL038},
  url     = {https://cds.cern.ch/record/2886522},
}

@Comment{jabref-meta: databaseType:bibtex;}
